\section{Discussion and Conclusions}
In this paper, we have proposed overlay accelerator systems based on two different memory interfaces, AXI and PCIe. 
The AXI-Xillybus-Overlay represents a very area efficient implementation compared with VectorBlox MXP-V16, but with about half of the throughput. 
AXI-Xillybus has only half the theoretical bandwidth of MXP, as Xillybus uses just 32-bits of an ACP port while MXP uses the full 64-bits of an HP port. 
If Xillybus were modified to use a 64-bit ACP port and two parallel V3 overlays were implemented, it would achieve a throughput close to MXP-V16, but with significantly fewer hardware resources (approximately 20\% of the LUTS and 8\% of the hard macros (BRAM and DSP) required by MXP on Zynq.
Thus, the linear TM overlay represents a relatively efficient implementation when FPGA resources are limited, as would be the case when an accelerator was used with other major subsystems in an FPGA based SoC design.

The PCIe-Xillybus-Overlay, RIFFA-Overlay and DyRACT-Overlay were also proposed for more high-performance centric accelerator systems. 
The DyRACT-Overlay has a 5.3$\times$ speed improvement when compared to the PCIe-Xillybus-Overlay, and a 45\% better throughput than the RIFFA-Overlay, achieving a throughput of 1892 MB/s on average. 
%Both DyRACT-Overlay and RIFFA-Overlay appear to be promising overlay accelerator for high computing purposes, however, 
There is a need to develop a full-duplex system for RIFFA-Overlay, which will not only reduce its BRAM utilization, but also potentially improve the throughput with parallel programming method. 
DyRACT-Overlay appears to be the most promising overlay accelerator for high computing purposes
%We open source the DyRACT-Overlay framework for future research and it can be downloaded from https://github.com/louislxw/linear\_tm\_overlay. 