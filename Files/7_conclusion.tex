\section{Discussion and Conclusions}
In this paper, we have proposed overlay accelerator systems based on two different memory interfaces, AXI and PCIe. 
The AXI-Xillybus-Overlay represents a very area efficient implementation compared with VectorBlox MXP-V16, but with about half of the throughput. 
AXI-Xillybus has only half the theoretical bandwidth of MXP, as Xillybus uses just 32-bits of an ACP port while MXP uses the full 64-bits of an HP port. 
If Xillybus were modified to use a 64-bit ACP port and two parallel V3 overlays were implemented, it would achieve a throughput close to MXP-V16, but with significantly fewer hardware resources (approximately 20\% of the LUTS and 8\% of the hard macros (BRAM and DSP) required by MXP on Zynq.
Thus, the linear TM overlay represents a relatively efficient implementation when FPGA resources are limited, as would be the case when an accelerator was used with other major subsystems in an FPGA based SoC design.

The PCIe-Xillybus-Overlay and RIFFA-Overlay were also proposed for more high-performance centric accelerator systems. 
The RIFFA-Overlay has a 3.6$\times$ speed improvement when compared to the PCIe-Xillybus-Overlay, and a 5.7$\times$ better throughput than the AXI-Xillybus-Overlay, achieving a throughput of 1300 MB/s on average. 
The RIFFA-Overlay appears to be the most promising overlay accelerator for high computing purposes, however, there is a need to develop a full-duplex system, which will not only reduce the BRAM utilization, but will also double the theoretical throughput.
